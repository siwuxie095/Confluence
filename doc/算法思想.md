[TOC]



# 数据结构与算法分析 Java 语言描述 原书第 3 版



（Data Structures and Algorithm Analysis in Java Third Edition）



作者：马克 · 艾伦 · 维斯（Mark Allen Weiss）

译者：冯舜玺、陈越

版次：2016 年 11 月第 1 版第 3 次印刷



出版社：机械工业出版社（China Machine Press）



PS：采用 Java 语言的形式。就翻译而言，不是很贴切。





## 递归简论




递归的四个基本法则：

（1）基准情形（base case）：必须总要有某些基准的情形，它无需递归就能解出。

（2）不断推进（making progress）：对于那些需要递归求解的情形，每一次递归调用都必须要使状况朝向一种基准情形推进。

（3）设计法则（design rule）：假设所有的递归调用都能运行。

（4）合成效益法则（compound interest rule）：在求解一个问题的同一实例时，切勿在不同的递归调用中做重复性的工作。



## 联机算法与脱机算法



定义？





## 算法设计技巧



用于求解问题的五种通常类型的算法。对于许多问题，很可能是这些方法中至少有一种方法是可以解决问题的。

（1）贪婪算法（greedy algorithm）

（2）分治算法（divide and conquer）

（3）动态规划（dynamic programming）

（4）随机化算法（randomized algorithm）

（5）回溯算法（backtracking）





### 贪婪算法（greedy algorithm）



贪婪算法分阶段的工作。在每个阶段，可以认为所做决定是好的，而不考虑将来的后果。通常，这意味着选择的是某个局部最优。这种 “眼下能够拿到的就拿” 的策略是这类算法名称的来源。当算法终止时，希望局部最优等于全局最优。如果是这样的话，那么算法就是正确的；否则，算法得到的是一个次最优解（suboptimal solution）。如果不要求绝对最佳答案，那么有时使用简单的贪婪算法生成近似的答案，而不是使用通常产生准确答案所需要的复杂算法。



常见应用：

Dijkstra 算法、Prim 算法、Kruskal 算法、辅币找零钱问题、哈夫曼算法（Huffman's algorithm，哈夫曼编码，用于文件压缩）、近视装箱问题（bin packing problem）





### 分治算法（divide and conquer）



分治算法由两部分组成：

（1）分（divide）：递归解决较小的问题（当然，基本情况除外）。

（2）治（conquer）：然后从子问题的解构建原问题的解。



传统上，在正文中至少含有两个递归调用的例程叫做分治算法，而正文中只含有一个递归调用的例程不是分治算法。一般坚持子问题是不相交的（即基本不重叠）。



分治算法的经典例子：归并排序和快速排序。



斐波那契数列的递归计算，虽然也可以被称为分治算法，但它的效率太低，因为问题实际上根本没有被分割。



所有有效的分治算法都是把问题分成一些子问题，每个子问题都是原问题的一部分，然后进行某些附加的工作以算出最后的答案。



常见应用：

归并排序、快速排序、最近点问题





### 动态规划（dynamic programming）



被数学上递归表示的问题也可以表示成一种递归算法，在许多情形下对朴素的穷举搜索得到显著的性能改进。



任何数据递推公式都可以直接转换成递归算法，但是基本现实是编译器常常不能正确对待递归算法，结果导致低效的程序。当怀疑很可能是这种情况时，必须再给编译器提供一些帮助，将递归算法重新写成非递归算法，让后者把那些子问题的答案系统地记录在一个表内。利用这种方法的一种技巧叫做动态规划。



用一个表代替递归。



动态规划是一种强大的算法设计技巧，它给解提供一个起点。它基本上是首先求解一些更简单问题的分治算法的范例，重要的区别在于这些更简单的问题不是原问题的明显的分割。因为子问题反复被求解，所以重要的是将它们的解记录在一个表中而不是重新计算它们。在某些情况下，解可以被改进（虽然这确实不总是明显的且常常是困难的），而在另一些情况下，动态规划方法则是所知道的最好的处理方法。



在某种意义上，如果你看出一个动态规划问题，那么你就看出所有的动态规划问题。



常见应用：

斐波那契数列、最优二叉查找树、所有点对最短路径





### 随机化算法（randomized algorithm）



在算法期间，随机数至少有一次用于决策。该算法的运行时间不只依赖于特定的输入，而且依赖于所出现的随机数。



一个随机化算法的最坏情形运行时间常常和非随机化算法的最坏情形运行时间相同。重要的区别在于，好的随机化算法没有坏的输入，而只有坏的随机数（相对于特定的输入）。



由于算法需要随机数，因此必须要有一种方法来生成它。实际上，真正的随机性在计算机上是不可能生成的，因为这些数将依赖于算法，从而不可能是随机的。一般说来，产生伪随机数（pseudorandom）就足够了，伪随机数看起来像是随机的数。随机数有许多已知的统计性质；伪随机数满足大部分的这些性质。



常见应用：

随机数发生器、跳跃表、素性测试





### 回溯算法（backtracking）



在许多情况下，回溯算法相当于穷举搜索的巧妙实现，但性能一般不理想。不过，情况并不总是如此，即使是如此，在某些情形下它相对于蛮力穷举搜索的工作量也有显著的节省。当然，性能是相对的：对于排序而言，O(N^2) 的算法是相当差的，但对旅行售货员（或任何 NP 完全）问题，O(N^5) 算法则是里程碑式的结果。



在一步内删除一大组可能性的做法叫做裁剪（pruning）。



常见应用：

收费公路重建问题、博弈（如西洋跳棋、国际象棋）







# 计算机算法设计与分析 第 5 版



作者：王晓东

版次：2018 年 8 月第 5 版第 1 次印刷



出版社：电子工业出版社（Publishing House of Electronics Industry）



采用 C++ 语言作为算法编程工具。



## 递归与分治策略



分治法的设计思想是：将一个难以直接解决的大问题分割成一些规模较小的相同问题，以便各个击破，即分而治之。如果原问题可分割成 k 个子问题，1 < k <= n，且这些子问题都可解，并可利用这些子问题的解求出原问题的解，那么这种分治法就是可行的。由分治法产生的子问题往往是原问题的较小模式，这为使用递归技术提供了方便。在这种情况下，反复应用分治手段，可以使子问题和原问题类型一致而规模不断缩小，最终使子问题缩小到容易求出其解，由此自然引出递归算法。分治与递归像一对孪生兄弟，经常同时应用在算法设计中，并由此产生许多高效算法。



### 递归的概念



直接或间接地调用自身的算法称为递归算法。用函数自身给出定义的函数称为递归函数。



使用递归技术往往使函数的定义和算法的描述简捷且易于理解。有些数据结构，如二叉树等，由于其本身固有的递归特性，特别适合用递归的形式来描述。有些问题，虽然其本身并没有明显的递归结构，但用递归技术来求解，可使设计出的算法简捷易懂且易于分析。



常见应用：

斐波那契数列、汉诺塔问题



### 分治法的基本思想



分治法的基本思想是将一个规模为 n 的问题分解为 k 个规模较小的子问题，这些子问题互相独立且与原问题相同。递归的解这些子问题，然后将各子问题的解合并得到原问题的解。它的一般的算法设计模式如下：

```java
divide-and-conquer(P) {
    if (|P| <= n0) 
        adhoc(P);
    divide P into smaller subinstances P1, P2, ..., Pk;
    for (i = 1; i <= k; i++) 
        yi = divide-and-conquer(Pi);
    return merge(y1, y2, ..., yk);
}
```



其中：
    |P| 表示问题 P 的规模，n0 为一阈值，表示当问题 P 的规模不超过 n0 时，问题容易解出，不必再继续分解。adhoc(P) 是该分治法的基本子算法，用于直接解小规模的问题 P。当 P 的规模不超过 n0 时，直接用算法 adhoc(P) 求解。算法 merge(y1, y2, ..., yk) 是该分治法中的合并子算法，用于将 P 的子问题 P1, P2, ..., Pk 的解 y1, y2, ..., yk 合并为 P 的解。



根据分治法的分割原则，应该把原问题分为多少个子问题才较适宜？每个子问题是否规模相同或怎样才为适当？这些问题很难予以肯定回答。但人们从大量实践中发现，在用分治法设计算法时，最好使子问题的规模大致相同，即将一个问题分成大小相等的 k 个子问题的处理方法是行之有效的。许多问题可以取 k=2。这种使子问题规模大致相等的做法出自一种平衡（balancing）子问题的思想，几乎总是比子问题规模不等的做法要好。



从分治法的一般设计模式可以看出，用它设计出的程序一般是递归算法，因此分治法的计算效率通常可以用递归方程来分析。



### 常见应用：

二分搜索（Binary Search）、大整数的乘法、Strassen 矩阵乘法、棋盘覆盖、合并排序（归并排序）、快速排序、线性时间选择、最接近点对问题、循环赛日程表





## 动态规划



动态规划算法与分治法类似，其基本思想是将待求解问题分解成若干子问题，先求解子问题，再结合这些子问题的解得到原问题的解。与分治法不同的是，适合用动态规划法求解的问题经分解得到的子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，以致最后解决原问题需要耗费指数级时间。然而，不同子问题的数目常常只有多项式量级。在用分治法求解时，有些子问题被重复计算了许多次。如果能够保存已解决的子问题的答案，在需要时再找出已求解的答案，这样可以避免大量的重复计算，从而得到多项式时间算法。为了达到此目的，可以用一个表来记录所有已解决的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思想。具体的动态规划算法多种多样，但它们具有相同的填表格式。



动态规划算法适用于解最优化问题，通常可以按以下 4 个步骤设计：

（1）分析最优解的结构：找出最优解的性质，并刻画其结构特征；

（2）建立递归关系：递归地定义最优值；

（3）计算最优值：以自底向上的方式计算最优值；

（4）构造最优解：根据计算最优值时得到的信息，构造最优解。



步骤（1）~（3）是动态规划算法的基本步骤。在只需要求出最优值的情形下，步骤（4）可以省略。若需要求出问题的最优解，则必须执行步骤（4）。此时，步骤（3）中计算最优值时，通常需记录更多的信息，以便在步骤（4）中，根据所记录的信息，快速构造出一个最优解。





### 动态规划算法的基本要素





动态规划算法的有效性依赖于问题本身所具有的两个重要性质：最优子结构性质和子问题重叠性质。



从一般意义上讲，问题所具有的这两个重要性质是该问题可用动态规划算法求解的基本要素。另外，动态规划还有一个变形：备忘录方法。



#### 1、最优子结构

设计动态规划算法的第一步通常是要刻画最优解的结构。当问题的最优解包含了其子问题的最优解时，称该问题具有最优子结构性质。问题的最优子结构性质提供了该问题可用动态规划算法求解的重要线索。



在动态规划算法中，利用问题的最优子结构性质，以自底向上的方式递归（应该是迭代）地从子问题的最优解逐步构造出整个问题的最优解。算法考察的子问题空间中规模较小。





#### 2、重叠子问题

可用动态规划算法求解的问题应具备的另一基本要素是子问题的重叠性质。在用递归算法自顶向下解此问题时，每次产生的子问题并不总是新问题，有些子问题被反复计算。动态规划算法正是利用了这种子问题的重叠性质，对每个子问题只解一次，然后将其解保存在一个表格中，当再次需要解此问题时，只是简单地用常数时间查看一下结果。通常，不同的子问题个数随问题的大小呈多项式增长。因此，用动态规划算法通常只需要多项式时间，从而获得较高的解题效率。





#### 3、备忘录方法

备忘录方法是动态规划的变形。与动态规划算法一样，备忘录方法用表格保存已解决的子问题的答案，在下次需要解此问题时，只需要简单地查看该子问题的解答，而不必重新计算。与动态规划算法不同的是，备忘录算法的递归方式是自顶向下的，而动态规划算法则是自底向上递归（应该是迭代）的。因此，备忘录方法的控制结构与直接递归的控制结构相同，区别在于备忘录方法为每个解过的子问题建立了备忘录以备需要时查看，避免了相同子问题重复求解。



备忘录方法为每个子问题建立一个记录项，初始化时，该记录项存入一个特殊的值，表示该子问题尚未求解。在求解过程中，对每个待求的子问题，首先查看其相应的记录项。若记录项中存储的是初始化时存入的特殊值，则表示该子问题是第一次遇到，此时计算出该子问题的解，并保存在其相应的记录项中，以备以后查看。若记录项中存储的已不是初始化时存入的特殊值，则表示该子问题已被计算过，其相应的记录项中存储的是该子问题的解答。此时，只要从记录项中取出该子问题的解答即可，而不必重新计算。



一般来讲，当一个问题的所有子问题都至少要解一次时，用动态规划算法比用备忘录方法好。此时，动态规划算法没有任何多余的计算。同时，对于许多问题，常可利用其规则的表格存取方式，减少动态规划算法的计算时间和空间需求。当子问题空间中的部分子问题可不必求解时，用备忘录方法则较有利，因为从其控制结构可以看出，该方法只解那些确实需要求解的子问题。





### 常见应用：

矩阵连乘问题、最长公共子序列、最大子段和、凸多边形最优三角剖分、多边形游戏、图像压缩、电路布线、流水作业调度、0-1背包问题、最优二叉搜索树、







## 贪心算法



当一个问题具有最优子结构性质时，可用动态规划法求解。有时会有更简单有效的算法。比如，找硬币的例子就适合用贪心算法。顾名思义，贪心算法总是做出在当前看来是最好的选择。也就是说，贪心算法并不从整体最优上加以考虑，所做的选择只是在某种意义上的局部最优选择。当然，我们希望贪心算法得到的最终结果也是整体最优的。



找硬币问题本身具有最优子结构性质，可以用动态规划算法来解，但贪心算法更简单，更直接，且解题效率更高。这利用了问题本身的一些特性。例如，找硬币算法利用了硬币面值的特殊性。虽然贪心算法不是对所有问题都能得到整体最优解，但对范围相当广的许多问题能产生整体最优解，如最小生成树问题、图的单源最短路径问题等。在一些情况下，即使贪心算法不能得到整体最优解，但其最终结果却是最优解的很好的近似解。



### 贪心算法的基本要素

贪心算法通过一系列选择来得到问题的解，所做的每个选择都是当前状态下局部最好的选择，即贪心选择。这种启发式的策略并不总能奏效，但在许多情况下确能达到预期目的。



对于一个具体的问题，怎么知道是否可用贪心算法来解此问题，以及能否得到问题的一个最优解呢？这个问题很难给予肯定的回答。但是，从许多可以用贪心算法求解的问题中可以看到，它们一般具有两个重要的性质：贪心选择性质和最优子结构性质。



#### 1、贪心选择性质

贪心选择性质是指，所求问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来达到。这是贪心算法可行的第一个基本要素，也是贪心算法与动态规划算法的主要区别。



在动态规划算法中，每步所做的选择往往依赖于相关子问题的解。因而只有解出相关子问题后，才能做出选择。



而在贪心算法中，仅在当前状态下做出最好选择，即局部最优选择。再去解做出这个选择后产生的相应的子问题。



贪心算法所做的贪心选择考研依赖以往所做过的选择，但决不依赖将来所做的选择，也不依赖子问题的解。正是由于这种差别，动态规划算法通常是以自底向上的方式解各子问题，贪心算法则通常以自顶向下的方式进行，以迭代的方式做出相继的贪心选择，每做一次贪心选择，就将所求问题简化为规模更小的子问题。



对于一个具体问题，要确定它是否具有贪心选择性质，必须证明每步所做的贪心选择最终导致问题的整体最优解。首先考察问题的一个整体最优解，并证明可修改这个最优解，使其以贪心选择开始。做了贪心选择后，原问题简化为规模更小的类似子问题。然后用数学归纳法证明，通过每一步做贪心选择，最终可得到问题的整体最优解。其中，证明贪心选择后的问题简化为规模更小的类似子问题的关键在于，利用该问题的最优子结构性质。



#### 2、最优子结构性质

当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质。问题的最优子结构性质是该问题可用动态规划算法或贪心算法求解的关键特征。







### 常见应用：

活动安排问题、最优装载问题、哈夫曼编码、单源最短路径、最小生成树、多机调度问题





## 回溯法

回溯法有 “通用的解题法” 之称，可以系统地搜索一个问题的所有解或任一解，它是一个既带有系统性又带有跳跃性的搜索算法。在问题的解空间树中，按深度优先策略，从根结点出发搜索解空间树，算法搜索至解空间树的任一结点时，先判断该结点是否包含问题的解，如果肯定不包含，则跳过对以该结点为根的子树的搜索，逐层向其祖先结点回溯；否则，进入该子树，继续按深度优先策略搜索。回溯法求问题的所有解时，要回溯到根，且根节点的所有子树都已被搜索到才结束。回溯法求问题的一个解时，只要搜索到问题的一个解就可结束。这种以深度优先的方式系统搜索问题解的算法称为回溯法，适合解组合数较大的问题。





### 回溯法的算法框架



#### 1、问题的解空间

用回溯法求解问题时，应明确定义问题的解空间。问题的解空间至少应包含问题的一个（最优）解。



定义了问题的解空间后，还应将解空间很好地组织起来，使得能用回溯法方便地搜索整个解空间。通常将解空间组织成树或图的形式。



#### 2、回溯法的基本思想

确定了解空间的组织结构后，回溯法从开始结点（根节点）出发，以深度优先方式搜索整个解空间。这个开始结点成为活结点，同时成为当前的扩展结点。在当前的扩展结点处，搜索向纵深方向移至一个新结点。这个新结点就成为新的活结点，并成为当前扩展结点。如果在当前的扩展结点处不能再向纵深方向移动，则当前扩展结点就成为死结点。此时，应往回移动（回溯）至最近的一个活结点处，并使这个活结点成为当前的扩展结点。回溯法以这种工作方式递归地在解空间中搜索，直至找到所要求的解或解空间中已无活结点时为止。



回溯法搜索解空间树时，通常采用两种策略来避免无效搜索，提高回溯法的搜索效率。其一是用约束函数在扩展结点处剪去不满足约束的子树，其二是用限界函数剪去得不到最优解的子树。这两类函数统称为剪枝函数。



综上所述，用回溯法解题通常包含以下 3 个步骤：

（1）针对所给问题，定义问题的解空间；

（2）确定易于搜索的解空间结构；

（3）以深度优先的方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。





#### 3、递归回溯

回溯法对解空间作深度优先搜索，因此在一般情况下可用递归函数来实现回溯法如下：

```java
void backtrack(int t) {
    if (t > n) {
        output(x);
    } else {
        for (int i = f(n, t); i <= g(n, t); i++) {
            x[t] = h(i);
        }
        if (constraint(t) && bound(t)) {
            backtrack(t + 1);
        }
    }
}
```



其中，形式参数 t 表示递归深度，即当前扩展结点在解空间树中的深度。n 用来控制递归深度，当 t > n 时，算法已搜索到叶结点。此时，由 output(x) 记录或输出得到可行解 x。算法 backtrack 的 for 循环中的 f(n, t) 和 g(n, t) 分别表示在当前扩展节点处未搜索过的子树的起始编号和终止编号。h(i) 表示在当前扩展结点处 x[t] 的第 i 个可选值。constraint(t) 和 bound(t) 表示在当前扩展结点处的约束函数和限界函数。constraint(t) 返回的值为 true 时，在当前扩展结点处 x[1:t] 的取值满足问题的约束条件，否则不满足问题的约束条件，可减去相应的子树。bound(t) 返回的值为 true 时，在当前扩展结点处 x[1:t] 的取值未使目标函数越界，还需由 backtrack(t + 1) 对其相应的子树做进一步的搜索。否则，当前扩展结点处 x[1:t] 的取值使目标函数越界，可减去相应的子树。执行了算法的 for 循环后，已搜索当前扩展结点的所有未搜索过的子树。backtrack(t) 执行完毕，返回 t - 1 层继续执行，对还没有测试过的 x[t-1] 的继续搜索。当 t = 1 时，若已测试完 x[1] 的所有可选值，外层调用就全部结束。显然，这一搜索过程按深度优先方式进行。调用一次 backtrack(1) 即可完成整个回溯搜索过程。



#### 4、迭代回溯

采用树的非递归深度优先遍历算法，也可将回溯法表示为一个非递归的迭代过程如下：

```java
void interativeBacktrack(void) {
    int t = 1;
    while (t > 0) {
        if (f(n, t) <= g(n, t)) {
            for (int i = f(n, t); i <= g(n, t); i++) {
                x[t] = h(i);
                if (constraint(t) && bound(t)) {
                    if(solution(t)) {
                        output(x);
                    } else {
                        t++;
                    }
                }   
            }
        } else {
            t--;
        }
    }
}
```



上述迭代回溯算法中，用 solution(t) 判断在当前扩展结点处是否已得到问题的可行解。它返回的值为 true 时，在当前扩展结点处 x[1:t] 是问题的可行解。此时，由 output(x) 记录或输出得到的可行解。它返回的值 false 时，在当前扩展结点处 x[1:t] 只是问题的部分解，还需向纵深方向继续搜索。算法中 f(n, t) 和 g(n, t) 分别表示在当前扩展结点处未搜索过的子树的起始编号和终止编号。h(i) 表示在当前扩展节点处 x[t] 的第 i 个可选值。constraint(t) 和 bound(t) 是当前扩展结点处的约束函数和限界函数。constraint(t) 返回的值为 true 时，在当前扩展结点处 x[1:t] 的取值满足问题的约束条件，否则不满足问题的约束条件，可剪去相应的子树。bound(t) 返回的值为 true 时，在当前扩展结点处 x[1:t] 的取值未使目标函数越界，还需对其相应的子树做进一步搜索。否则，当前扩展结点处 x[1:t] 的取值已使目标函数越界，可剪去相应的子树。算法的 while 循环结束后，完成整个回溯搜索过程。



用回溯法阶解题的一个显著特征是，在搜索过程中动态产生问题的解空间。在任何时刻，算法只保存从根结点到当前扩展结点的路径。如果解空间树中从根结点到叶结点的最长路径的长度为 h(n)，则回溯法所需的计算空间通常为 O(h(n))。显式地存储整个解空间则需要 O(2^h(n)) 或 O(h(n)!) 内存空间。



#### 5、子集树与排列树

用回溯法解题时常遇到的两类典型的解空间树是：子集树和排列树。



当所给的问题是从 n 个元素的集合 S 中找出某种性质的子集时，相应的解空间树称为子集树。例如，n 个物品的 0-1 背包问题所相应的解空间树就是一棵子集树。这类子集树通常有 2^n 个叶结点，其结点总个数为 2^(n+1) - 1。遍历子集树的任何算法均需 O(2^n) 的计算时间。



当所给的问题是确定 n 个元素满足某种性质的排列时，相应的解空间树称为排列树。排列树通常有 n! 个叶结点。因此遍历排列树需要 O(n!) 的计算时间。例如，旅行售货员问题的解空间树就是一棵排列树。



用回溯法搜索子集树的一般算法可描述如下：

```java
void backtrack(int t) {
    if (t > n) {
        output(x);
    } else {
        for (int i = 0; i <= 1; i++) {
            x[t] = i;
            if (constraint(t) && bound(t)) 
            	backtrack(t + 1);
        }
    }
}
```



用回溯法搜索排列树的算法框架可描述如下：

```java
void backtrack(int t) {
    if (t > n) {
        output(x);
    } else {
        for (int i = 0; i <= 1; i++) {
            swap(x[t], x[i]);
            if (constraint(t) && bound(t)) 
            	backtrack(t + 1);
            swap(x[t], x[i]);
        }
    }
}
```

在调用 backtrack(1) 执行回溯搜索前，先将变量数组 x 初始化为单位排列 (1, 2, ..., n)。

 

### 常见应用：

装载问题、批处理作业调度、符号三角形问题、n后问题、0-1背包问题、最大团问题、图的m着色问题、旅行售货员问题、圆排列问题、电路板排列问题、连续邮资问题





## 分支限界法

分支限界法类似回溯法，也是在问题的解空间上搜索问题解的算法。一般情况下，分支限界法与回溯法的求解目标不同。回溯法的求解目标是找出解空间中满足约束条件的所有解，而分支限界法的求解目标是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。



由于求解目前不同，导致分支限界法与回溯法对解空间的搜索方式也不同。回溯法以深度优先的方式搜索解空间，分支限界法则以广度优先或以最小耗费优先的方式搜索解空间。分支限界法的搜索策略是，在扩展结点处，先生成其所有儿子结点（分支），再从当前的活结点表中选择下一个扩展结点。为了有效地选择下一扩展结点，加速搜索的进程，在每个活结点处，计算一个函数值（限界），并根据函数值，从当前活结点表中选择一个最有利的结点作为扩展结点，使搜索朝着解空间上有最优解的分支推进，以便尽快地找出一个最优解。这种方法称为分支限界法。人们已经用分支限界法解决了大量离散优化问题。



### 分支限界法的基本思想



分支限界法常以广度优先或最小耗费（最大效益）优先的方式搜索问题的解空间树。问题的解空间树是表示问题解空间的一棵有序树，常见的有子集树和排列树。在搜索问题的解空间树时，分支限界法与回溯法的主要区别在于它们对当前扩展结点所采用的扩展方式不同。



在分支限界法中，每个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点列表中。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所需的解或活结点表为空时为止。



从活结点表中选择下一扩展结点的不同方式导致不同的分支限界法。最常见的有以下两种方式。



#### 1、队列式（FIFO）分支限界法



队列式分支限界法将活结点表组织成一个队列，并按队列的先进先出原则选取下一结点为当前扩展结点。



#### 2、优先队列式分支限界法



优先队列式的分支限界法将活结点表组织成一个优先队列，并按优先队列中规定的结点优先级选取优先级最高的下一个结点成为当前扩展结点。



优先队列中规定的结点优先级常用一个与该结点相关的数值 p 来表示。结点优先级的高低与 p 值的大小相关。最大优先队列规定 p 值较大的结点优先级较高。在算法实现时，通常用最大堆来实现最大优先队列，用最大堆的 deleteMax 运算抽取堆中下一个结点成为当前扩展结点，体现最大效益优先的原则。类似地，最小优先队列规定 p 值较小的结点优先级较高。在算法实现时，通常用最小堆来实现最小优先队列，用最小堆的 deleteMin 运算抽取堆中下一个结点成为当前扩展结点，体现最小费用优先原则。



用优先队列式分支限界法解具体问题时，应根据具体问题的特点确定选用最大优先队列或最小优先队列来表示解空间的活结点表。



在寻求问题的最优解时，与讨论回溯法时类似，可以用剪枝函数加速搜索。该函数给出每一个可行结点相应的子树可能获得的最大价值的上界。如果这个上界不会比当前最优值更大，则说明相应的子树中不含问题的最优解，因而可以剪去。另一方面，可以将上界函数确定的每个结点的上界值作为优先级，以该优先级的非增序抽取当前扩展结点。这种策略有时可以更迅速地找到最优解。



或者可以用一个限界函数在搜索过程中裁剪子树，以减少产生的活结点。此时剪枝函数是当前节点扩展后得到的最小费用的下界。如果在当前扩展结点处，这个下界不比当前最优值更小，则剪去以该结点为根的子树。另一方面，可以把每个结点的下界作为优先级，依非减序从活结点优先队列中抽取下一个扩展结点。









### 常用应用：

单源最短路径问题、装载问题、布线问题、0-1 背包问题、最大团问题、旅行售货员问题、电路板排列问题、批处理作业调度问题





## 随机化算法



随机化算法大致分为 4 类：

（1）数值随机化算法

（2）蒙特卡罗（Monte Carlo）算法

（3）拉斯维加斯（Las Vegas）算法

（4）舍伍德（Sherwood）算法







## 线性规划与网络流

暂时不必看



## 串与序列的算法

KMP、后缀数组、编辑距离









# 算法设计与分析基础 第 3 版



（Introduction to The Design and  Analysis of Algorithm Third Edition）



作者：Anany Levitin

译者：潘彦

版次：2015 年 2 月第 3 版第 1 次印刷



出版社：清华大学出版社



作者基于丰富的教学经验，开发了一套全新的算法分类方法。该分类法站在通用问题求解策略的高度，对现有大多数算法准确分类，从而引领读者沿着一条清晰、一致、连贯的思路来探索算法设计与分析这一迷人领域。

这里讨论了 10 种通用设计技术：
（1）蛮力法
（2）分治法
（3）减治法
（4）变治法
（5）时空权衡
（6）动态规划
（7）贪婪技术
（8）迭代改进
（9）回溯法
（10）分支界限法

以上算法都属于顺序算法（sequential algorithm），这里没有涉及到的算法有：随机算法（randomized algorithm）和并行算法（parallel algorithm）。


PS：采用伪代码的形式。


## 蛮力法

蛮力法（Brute force）是一种简单直接地解决问题的方法，常常直接基于问题的描述和所涉及的概念定义。

PS：也称为暴力法，即 暴力破解。

这里的 “力” 是指计算机的计算 “能力”，而不是人的 “智力”。也可以用 “just do it” 来描述蛮力法的策略。而且一般来说，蛮力策略也常常是最容易应用的方法。

虽然巧妙和高效的算法很少来自于蛮力法，但我们不应该忽略它作为一种重要的算法设计策略的地位。第一，和其他某些策略不同，我们可以应用蛮力法来解决广阔领域的各种问题。实际上，它可能是唯一一种几乎什么问题都能解决的一般性方法。第二，对于一些重要的问题（例如，排序、查找、矩阵乘法和字符串匹配）来说，蛮力法可以产生一些合理的算法，它们多少具备一些实用价值，而且不必限制实例的规模。第三，如果要解决的问题实例不多，而且蛮力法可以用一种能够接受的速度对实例求解，那么，设计一个更高效算法所花费的代价很可能是不值得的。第四，即使效率通常很低，仍然可以用蛮力算法解决一些小规模的问题实例。第五，蛮力算法可以为研究或教学目的服务，例如，可以以之为准绳，来衡量同样问题的更高效算法。

### 穷举查找

许多重要的问题要求在一个复杂度随实例规模指数增长（或者更快）的域中，查找一个具有特定属性的元素。无论是明指还是暗指，一般来说，这种问题往往涉及组合对象，例如排列、组合以及一个给定集合的子集。许多这样的问题都是最优问题：它们要求找到一个元素，能使某些期望的特性最大化或者最小化，例如路径的长度或者分配的成本。

对于组合问题来说，穷举查找（exhaustive search）是一种简单的蛮力方法。它要求生成问题域中的每一个元素，选出其中满足问题约束的元素，然后再找出一个期望元素（例如，使目标函数达到最优的元素）。注意，虽然穷举查找的思想很简单直接，但在实现时，它常常会要求一个算法来生成某些组合对象。例如旅行商问题（traveling salesman problem，TSP）、背包问题以及分配问题。

### 小结

（1）蛮力法是一种简单直接地解决问题的方法，通常直接基于问题的描述和所涉及的概念定义。
（2）蛮力法的主要优点是它广泛的适用性和简单性，主要缺点是大多数蛮力算法的效率都不高。
（3）蛮力法的第一个应用就是得出一个算法，此算法可以通过适度的努力来提升它的性能。
（4）下列这些著名的算法可以看作蛮力法的例子：
1）基于定义的矩阵乘法算法
2）选择排序
3）顺序查找
4）简单的字符串匹配算法
（5）穷举查找是解组合问题的一种蛮力方法。它要求生成问题中的每一个组合对象，选出其中满足该问题约束的对象，然后找出一个期望的对象。
（6）旅行商问题、背包问题和分配问题是典型的能够用穷举查找算法求解的问题，至少在理论上是这样。
（7）除了相关问题的一些规模非常小的实例，穷举查找法几乎是不实用的。
（8）深度优先查找（DFS）和广度优先查找（BFS）是两个非常重要的图遍历算法。通过构造图的深度优先查找或者广度优先查找森林，可以帮助研究图的许多重要性质。两个算法的时间效率是相同的：对于领接矩阵结构的时间效率是 O(V^2)，链表结构的时间效率是 O(V+E)。





## 减治法

减治（derease-and-conquer）技术利用了一个问题给定实例的解和同样问题较小实例的解之间的某种关系。一旦建立了这种关系，我们既可以从顶至下，也可以从底至上地来运用该关系。虽然自顶向下会自然导致出递归算法，但从实践来看，最终还是非递归实现较好。自底向上版本往往是迭代实现的，从求解问题的一个较小实例开始，该方法有时也称为增量法（Incremental Approach）。

减治法有 3 种主要的变化形式：
（1）减去一个常量
（2）减去一个常量因子
（3）减去的规模是可变的

在减常量（decrease-by-a-constant）变化形式中，每次算法迭代总是从实例中减去一个相同的常量。一般来说，这个常量等于 1，但减其他常量的情况偶尔也会出现。

减常因子技术意味着在算法的每次迭代中，总是从实例的规模中减去一个相同的常数因子。在大多数应用中，这样的常数因子等于 2（也就是减半思想）。

最后，在减可变规模（variable-size-decrease）的变化形式中，算法在每次迭代时，规模减小的模式都是不同的。计算最大公约数的欧几里得算法是这种情况的一个很好的例子。这个算法基于以下公式：gcd(m, n) = gcd(n, m mod n)

### 小结

（1）减治法是一种一般性的算法设计技术，它利用了一个问题给定实例的解和同样问题较小实例的解之间的关系。一旦建立这样一种关系，我们既可以自顶至下（递归）也可以自底至上地运用这种关系。
（2）减治法有 3 种主要的变化形式：
1）减一个常量，常常是减一（例如插入排序）。
2）减一个常因子，常常是减去因子 2（例如折半查找）。
3）减可变规模（例如欧几里得算法）。
（3）插入排序是减治（减一）技术在排序问题上的直接应用。无论在平均情况还是最差情况下，它都是 O(n^2) 的算法，但在平均情况下的效率大约要比最差情况下快一倍。该算法一个较为出众的优势在于，对于几乎有序的数组，它的性能是很好的。
（4）一个有向图是一个对边指定了方向的图。拓扑排序要求按照这种次序列出它的顶点，使得对于图中每一条边来说，边的起始顶点总是排在边的结束顶点之前。当且仅当有向图是一个无环有向图（不包含回路的有向图）时，该问题有解，也就是说，它不包含有向的回路。
（5）解决拓扑排序问题有两种算法。第一种算法基于深度优先查找，第二种算法基于减一技术的直接应用。
（6）在设计生成基本组合对象的算法时，减一技术是一种非常自然的选择。这类算法中最高效的类型是最小变化算法。然而，组合对象的数量增长的如此之快，使得实际应用中，即使最高效的算法也只能用来解决这类问题的一些非常小的实例。
（7）折半查找时一种非常有效的搜索有序数组的算法。它是减常因子算法的一个重要例子。其他例子包括：平方求幂、天平选假币、俄式乘法以及约瑟夫斯问题。
（8）对于某些基于减治技术的算法，在算法的一次迭代和另一次迭代时消减的规模是变化的。这种减可变规模算法的例子包括欧几里得算法、选择问题的基于划分的算法、插值查找和二叉查找树中的查找及插入操作。我们还以拈游戏为例介绍了这样一种小游戏，它们是一系列步骤来完成游戏的，每一步都使该游戏变成一个更小的实例。




## 分治法

分治法（divide-and-conquer）可能是最著名的通用算法设计技术了。虽然它的名气可能和它那好记的名字有关，但它的确是当之无愧的：很多非常有效的算法实际上就是这个通用算法的特殊实现。其实，分治法是按照以下方案工作的。
（1）将一个问题划分为同一类型的若干子问题，子问题最好规模相同。
（2）对这些子问题求解（一般使用递归方法，但在问题规模足够小时，有时也会利用另一个算法）。
（3）有必要的话，合并这些子问题的解，以得到原始问题的答案。

递推式：T(n) = aT(n/b) + f(n)，也被称为通用分治递推式（divide-and-conquer recurrence）。

### 小结

（1）分治法是一种一般性的算法设计技术，它将问题的实例划分为若干个较小的实例（最好拥有同样的规模），对这些较小的实例递归求解，然后合并这些解，以得到原始问题的解。许多高效的算法都是基于这种技术的，虽然有时候它的适应性和效率并不如一些更简单的算法。
（2）许多分支算法的时间效率 T(n) 满足方程 T(n) = aT(n/b) + f(n)。主定理确定了该方程解的增长次数。
（3）合并排序是一种分治排序算法。它把一个输入数组一分为二，并对它们递归排序，然后把这两个排好序的子数组合并为原数组的一个有序排列。在任何情况下，这个算法的时间效率都是 O(nlogn)，而且它的键值比较次数非常接近理论上的最小值。它的主要缺点是需要相当大的额外存储空间。
（4）快速排序是一种分治排序算法，它根据元素值和某些事先确定的元素的比较结果，来对输入元素进行划分。快速排序十分有名，这不仅因为对于随机排列的数组，它是一种较为出众的 nlogn 效率算法，而且因为它的最差效率是平方级的。
（5）二叉树的经典遍历算法（前序、中序、后序）和其他类似的算法都需要递归处理左右两棵子树，它们都可以当做分治技术的例子。用一些特定的外部节点来替代给定树的空子树，有助于对这些算法进行分析。
（6）有一种处理两个 n 位整数相乘的分治算法，大约需要做 n^1.585 次一位数乘法。
（7）Strassen 算法只需要做 7 次乘法就能计算出两个 2×2 矩阵的积，但比基于定义的算法要做更多次的加法。利用分治技术，该算法计算两个 n×n 矩阵的乘法时需要做 n^2.807 次乘法。
（8）分治技术可以成功地应用于两个重要的计算几何问题：最近对问题和凸包问题。





## 变治法

有这样一组设计方法，它们都是基于变换的思想。把这种通用技术称为变治法（transform-and-conquer），因为这些方法都是分成两个阶段工作的。首先，在 “变” 的阶段，出于这样或那样的原因，把问题的实例变得更容易求解。然后，在第二阶段或者或 “治” 的阶段，对实例进行求解。

根据我们对问题实例的变换方式，变治思想有 3 种主要的类型：
（1）变换为同样问题的一个更简单或更方便的实例，称之为实例化简（instance simplification）。
（2）变换为同样实例的不同表现，称之为改变表现（representation change）。
（3）变换为另一个问题的实例，这种问题的算法是已知的，称之为问题化简（problem reduction）。

即 更简单的实例、另一种表现、另一个问题的实例 三种。


### 小结

（1）变治法是一种通用算法设计（问题求解）策略。实际上，这是一组基于变换思想的技术，用来把问题变换成一种更容易解决的类型。
（2）变治技术有三种主要的类型：实例化简、改变表现和问题化简。
（3）实例化简是一种把问题的实例变换成相同问题的另一个实例的技术，这个新的实例有一些特殊的属性，使得它更容易被解决。列表预排序、高斯消去法和 AVL 树都是这种技术的好例子。
（4）改变表现指的是将一个问题实例的表现改变为同样实例的另一种表现。例如，用 2-3 树表示集合、堆和堆排序、求多项式的霍纳法则以及两种二进制幂算法。
（5）问题化简提倡把一个给定的问题变换为另一个可以用已知算法求解的问题。在那些应用了这个思想的算法解题中，化简为线性规划问题和化简为图问题是尤其重要的。
（6）一些用来阐述变治技术的例子恰好是非常重要的数据结构和算法。它们是：堆和堆排序、AVL 树和 2-3 树、高斯消去法以及霍纳法则。
（7）堆是一棵基本完备二叉树，它的键都满足父母优势要求，虽然定义为二叉树，但一般用数组来实现堆。堆对于优先队列的高效实现来说尤为重要，同时，堆还是堆排序的基础。
（8）堆排序在理论基础上是一种重要的排序算法，它的基本思路是，在排列好堆中的数组元素后，再从剩余的堆中连续删除最大的元素。无论在最差情况下还是在平均情况下，该算法的运行时间都属于 O(nlogn)，而且，它还是在位的排序算法。
（9）AVL 树是一种二叉树可能达到的广度上尽量平衡的二叉查找树。平衡是由四种称为旋转的变换来维持的。AVL 树上的所有基本操作都属于 O(logn)，它消除了经典二叉查找树在最差效率上的弊端。
（10）2-3 树是一种达到了完美平衡的查找树，它允许一个节点最多包含两个键和三个子女。这个思想推而广之，会产生一种非常重要的 B 树。
（11）高斯消去法是一种解线性方程组的算法，它是线性代数中的一种基本算法。它通过把方程组变换为一个具有上三角形系数矩阵的方程组来解题，这种方程组很容易用反向替换法求解。高斯消去法大约需要 (n^3)/3 次乘法运算。
（12）在无需对系数进行预处理的多项式求解算法中，霍纳法则是最优的，它只需要 n 次乘法和 n 次加法。它还有一些有用的副产品，例如综合除法算法。
（13）这里还介绍了两种计算 a^n 的二进制幂算法。它们都使用了指数 n 的二进制表示，但它们按照相反的方向对其进行处理：从左到右和从右到左。
（14）线性规划关心的是最优化一个包含若干变量的线性函数，这个函数受到一些形式为线性等式和线性不等式的约束。有一些高效的算法可以对这个问题的庞大实例求解，它们包含了成千上万的变量和约束，但不能要求变量必须是整数。如果变量一定要是整数，我们称之为整数线性规划问题，这类问题的难度要高很多。







## 时空权衡

无论对于计算机理论工作者还是计算机实践工作者来说，算法设计中的时空权衡都是一个众所周知的问题。作为一个例子，考虑一下在函数定义域的多个点上计算函数值的问题。如果运算时间更为重要的话，我们可以事先把函数值计算好并将它们存储在一张表中。这就是在电子计算机发明前，“人工计算机” 所做的工作，那时的图书馆也被厚重的数学用表堆满了。虽然随着电子计算机的广泛应用，这些数学用表失去了大部分的吸引力，但事实证明，在开发一些用于其他问题的重要算法时，它们的基本思想还是非常有用的。按照一种更一般的表述，这个思想是对问题的部分或全部输入做预处理，然后将获得的额外信息进行存储，以加速后面问题的求解。我们把这个方法称为输入增强（input enhancement）。下面这些算法都是以它为基础的：
（1）计数法排序。
（2）Boyer-Moore 字符串匹配算法和霍斯普尔提出的简化版本。

PS：输入增强的同义标准术语：预处理（preprocessing）和预调节（preconditioning）。


其他采用空间换时间权衡思想的技术简单地使用额外空间来实现更快和（或）更方便的数据存取。我们把这种方法称为预构造（prestructuring）。这个名字强调了这种空间换时间权衡技术的两个方面：所讨论的问题在实际处理之前已经做过某些预处理了；但和输入增强技术不同，这个技术只涉及存取结构。有两个例子可以说明这个问题：
（1）散列法。
（2）以 B 树作索引。

还有一种和空间换时间权衡思想相关的算法设计技术：动态规划（dynamic programming）。这个策略的基础是把给定问题中重复子问题的解记录在表中，然后求得所讨论问题的解。

最后还要对算法设计中时间和空间的相互作用做两点说明：首先，并不是在所有的情况下，时间和空间这两种资源都必须相互竞争。实际上，它们可以联合起来，使得一个算法无论在运行时间还是消耗的空间上都达到最小化。具体来说，这种情况出现在一个算法使用了一种空间效率很高的数据结构来表示问题的输入，这种结构又会反过来提高算法的时间效率的时候。作为一个例子，考虑图的遍历问题。回忆一下两种主要的遍历算法（深度优先查找和广度优先查找），它们的时间效率依赖于表示图的数据结构：对于邻接矩阵表示法是 O(n^2)，对于邻接链表表示法是 O(n+m)，其中 n 和 m 分别是顶点和边的数量。如果输入图是稀疏的，也就说，相对于顶点的数量来说，边的数量并不多，无论从空间角度还是从运行时间的角度来看，邻接链表表示法的效率都会更高一些。在处理稀疏矩阵和稀疏多项式时也会有相同的情况：如果在这些对象中，0 所占的百分比足够高，在表示和处理对象时把 0 忽略，则既可以节约空间，也可以节约时间。

其次，在讨论空间换时间权衡技术时，无法不提到数据压缩这个重要领域。然而，必须强调，数据压缩的主要目的是节约空间而不是作为解决另一个问题的一项技术。


### 小结

（1）无论对于计算机理论工作者还是计算机实践工作者来说，算法设计中的时空权衡都是一个众所周知的问题。作为一种算法设计技术，空间换时间要比时间换空间普遍得多。
（2）在算法设计中，空间换时间技术有两种主要类型，输入增强是其中一种。它的思想是对问题输入的部分或全部做预处理，然后将获得的额外信息进行存储，以加速后面问题的解决。用分布计数进行排序以及一些重要的字符串匹配算法都是基于这个技术的算法。
（3）分布计数是一种特殊的方法，用来对元素取值来自于一个小集合的列表排序。
（4）用于字符串匹配的 Horspool 算法可以看作 Boyer-Moore 算法的一个简化版本。两个算法都以输入增强思想为基础，并且从右向左比较模式中的字符。两个算法都是用同样的坏符号移动表。Boyer-Moore 算法还使用了第二个表，称为好后缀移动表。
（5）第二种使用了空间换时间权衡思想的技术称为预构造，它使用额外的空间来实现更快和（或）更方便的数据存取。散列和 B 树是预构造的重要例子。
（6）散列是一种非常高效的实现字典的方法。它的基本思想是把键映射到一张一维表中。这种表在大小上的限制使得它必须采用一种碰撞解决机制。散列的两种主要类型是开散列（又称为分离链，键存储在散列表以外的链表中）以及闭散列（又称为开式寻址，键存储在散列表中）。平均情况下，这两种算法的查找、插入和删除操作的效率都是属于 O(1) 的。
（7）B 树是一棵平衡查找树，它把 2-3 树的思想推广到允许多个键位于同一个节点上。它的主要作用是维护存储在磁盘上的数据的类索引信息。通过选择恰当的树的次数，即使对于非常大的文件，我们所实现的查找、插入和删除操作也只需要执行很少几次的磁盘存取。





## 动态规划

动态规划（dynamic programming）是一种算法设计技术，它有着相当有趣的历史。作为一种使用多阶段决策过程最优的通用方法。它是在 20 世纪 50 年代由一位卓越的美国数学家理查德 · 贝尔曼（Richard Bellman）发明的。因此，这个技术名字中的 “programming” 是计划和规划的意思，不是代表计算机中的编程。它不仅是应用数学中用来解决某类最优问题的重要工具，而且还在计算机领域中被当做一种通用的算法设计技术来使用。在这里，我们正是从这个角度来考虑这种技术的。

如果问题是由交叠的子问题构成的，我们就可以用动态规划技术来解决它。一般来说，这样的子问题出现在对给定问题求解的递推关系中，这个递推关系中包含了相同类型的更小子问题的解。动态规划法建议，与其对交叠的子问题一次又一次地求解，还不如对每个较小的子问题只求解一次并把结果记录在表中，这样就可以从表中得出原始问题的解。

虽然动态规划法的直接应用也可以解释成一种特殊类型的空间换时间权衡技术，但有时候一个动态规划算法经过改进可以避免使用额外的空间。

一般来说，一个算法如果基于经典的从底至上动态规划方法，那就需要解出给定问题的所有较小子问题。动态规划法的一个变化形式试图避免对不必要的子问题求解。也就是利用了一种所谓的记忆功能，我们可以把它看作动态规划的一种从顶至下的变化形式。

但无论使用动态规划的经典的从底至上版本还是它基于记忆功能的从顶至下版本，设计这样一种算法的关键步骤还是相同的，即导出一个问题实例的递推关系，该递推关系包含该问题的更小（并且是交叠的）子实例的解。

由于动态规划的大多数应用都是求解最优化问题，因此需要指出这类应用中的一个一般性法则。理查德 · 贝尔曼称其为最优化法则（principe of optimality）。该法则认为最优化问题任一实例的最优解，都是由其子实例的最优解构成的。最优化法则在大多数情况下是成立的，尽管也有少数情况例外（一个相当罕见的例子，就是在图中找最长简单路径）。虽然在应用动态规划求解具体问题时，需要检查最优化法则是否适用，但在设计动态规划算法时，做一个这样的检查并不困难。


### 小结

（1）动态规划方法是一种对具有交叠子问题的问题进行求解的技术。一般来说，这样的子问题出现在求解给定问题的递推关系中，这个递推关系中包含了相同类型的更小子问题的解。动态规划法建议，与其对交叠的子问题一次又一次地求解，还不如对每个较小的子问题只解一次并把结果记录在表中，这样就可以从表中得出原始问题的解。
（2）对一个最优问题应用动态规划方法要求该问题满足最优化法则：一个最优问题的任何实例的最优解是由该实例的子实例的最优解组成的。
（3）和许多其他问题一样，任意面额的硬币找零问题可以用动态规划方法求解。
（4）用动态规划算法求解背包问题可以作为应用该技术求解组合难题的例证。
（5）记忆功能技术试图把自顶向下和自底向上方法的优势结合起来，对具有交叠子问题的问题求解。它用自顶向下的方式，对给定问题的必要子问题只求解一次，并它们的解记录在表中。
（6）如果已知键的一个集合以及它们的查找效率，可以使用动态规划方法来构造一棵最优二叉查找树。
（7）求传递闭包的 Warshall 算法和求完全最短路径问题的 Floyd 算法都基于同一思想，可以把这种思想解释为动态规划技术的一种应用。


## 贪婪技术

对找零问题应用的方法被称为贪婪法（greedy）。尽管实际上这个方法只能应用于最优问题，但计算机科学家把它当作一种通用的设计技术。贪婪法建议通过一系列步骤来构造问题的解，每一步对目前构造的部分解做一个扩展，直到获得问题的完整解为止。这个技术的核心是，所做的每一步选择都必须满足以下条件。
（1）可行的（feasible）：即它必须满足问题的约束。
（2）局部最优的（locally optimal）：它是当前步骤中所有可行选择中最佳的局部选择。
（3）不可取消（irrevocable）：即选择一旦做出，在算法的后面步骤中就无法改变了。

这些要求对这种技术的名称做出了解释：在每一步中，它要求 “贪婪” 地选择最佳操作，并希望通过一系列局部的最优选择，能够产生一个整个问题的（全局的）最优解。我们尽量避免从哲学的角度来讨论贪婪是好还是不好。从算法的角度来看，这个问题应该是，贪婪算法是否是有效的。在实际中，的确存在某些类型的问题，一系列局部的最优选择对于它们的每一个实例都能够产生一个最优解。然而，还有一些问题并不是这种情况。对于这样的问题，如果我们关系的是近似解，或者我们只能满足于近似解，贪婪算法仍然是有价值的。

常见应用如：Prim 算法、Kruskal 算法、Dijkstra 算法、哈夫曼树（哈夫曼编码）。

通常来说，贪婪算法看上去既直观又简单。给定一个最优化问题，考虑几个小规模的问题实例后，通常容易得出如何以贪婪的方式处理该问题。通常最困难的是如何证明某一贪婪算法能获得最优解（如果可以获得最优解）。一个常用的证明方法是使用数学归纳法，可以证明贪婪算法在每一步获得的部分解能够扩展到全局最优解。

为了证明贪婪算法的能够获得最优解，第二个办法是证明在接近问题目标的过程中，贪婪算法每一步的选择至少不比任何其他算法差。

第三种证明法是基于算法的输出，而不是它执行的操作，来证明贪婪算法获得的最终解的最优性。

最后，我们应当提及贪婪技术背后一个相当复杂的理论，它是基于一种称为 “拟阵” 的抽象组合结构。


### 小结

（1）贪婪技术建议通过一系列步骤来构造问题的解，每一步对目前构造的部分解做一个扩展，直到获得问题的完整解为止。这个技术的核心是，所做的每一步选择都必须满足可行、局部最优和不可取消原则。
（2）Prim 算法是一种为加权连通图构造最小生成树的贪婪算法。它的工作原理是向前面构造的一棵子树中添加离树中顶点最近的顶点。
（3）Kruskal 算法是另一种最小生成树问题的算法。它按照权重的升序把边包含进来，以构造一棵最小生成树，并使得这种包含不会产生一条回路。为了保证这种检查的效率，需要应用一种所谓的并查算法。
（4）Dijkstra 算法解决了单起点最短路径问题，该问题要求从给定的顶点（起点）出发通向加权图或者有向图的其他所有顶点的最短路径。它的工作过程和 Prim 算法是一样的，不同点在于它比较的是路径的长度而不是边的长度。对于不含负权重的图，Dijkstra 算法总是能够产生一个正确的解。
（5）哈夫曼树是一棵二叉树，它使得从根出发到包含一组预定义权重的叶子之间的加权路径长度达到最小。哈夫曼树最重要的应用是哈夫曼编码。
（6）哈夫曼编码时一种最优的自由前缀变长编码方案，它基于字符在给定文本中的出现频率，把位串赋给字符。这是通过贪婪地构造一棵二叉树来完成的，二叉树的叶子代表字母表中的字符，而树中的边则标记为 0 或者 1。



## 迭代改进

对于之前的贪婪策略来说，喜欢一点一点地构造最优问题的解，每次总是把一个局部最优解加入一个部分构造解之中。这里将尝试一种不同的方法来设计最优问题的算法。它从某些可行解（一个满足问题所有约束的解）出发，通过重复应用一些简单的步骤来不断改进它。这些步骤一般会通过一些小的、局部的改变来生成一个可行解，这个解使得目标函数值更为优化。如果目标函数值无法再得到优化，该算法就把最后的可行解作为最优解返回，然后算法就结束了。

要顺利实现这一思想可能会遇到几个障碍。第一，我们需要一个初始的可行解。对于某些问题来说，我们总是可以从一个平凡解开始，或者是其他算法（例如贪婪算法）所生成的近似解。但对另一些问题来说，求一个初始解也不容易，可能和可行解找到后求解该问题所花的力气是一样多的。第二，对可行解应该做什么样的改变并不总是一目了然的。第三，也是最根本的困难，就是局部极值和全局极值（最大或最小）的问题。想一想，如果没有地图，要在浓雾天找到一个山区的最高点是多么困难。一个合乎逻辑的做法是从所在的点出发，沿着山向上走。但总会走到一个没法向上走的点，这个做法就不得不停止了。这时，我们可能遇到了一个局部最高点，但因为我们无法穷尽所有的可能性，所以没有一个简单的方法可以告诉我们该点是不是整个山区的最高点（这就是全局最大的问题）。

幸运的是，有一些重要的问题可以用迭代改进来求解。其中最重要的就是线性规划问题。其中，单纯形法，这是线性规划的经典算法。

### 小结

（1）迭代改进技术用来求最优问题的解，它生成一系列使问题的目标函数值不断改进的可行解。这一系列可行解中，后续解相比前面的解一般总是有些小的、局部的改变。如果目标函数值无法再得到优化，该算法就把最后的可行解作为最优解返回，然后算法就结束了。
（2）正好可以用迭代改进算法求解的重要问题包括线性规划、网络流量最大化以及图的最大数量顶点匹配问题。
（3）单纯形法是求解一般线性规划问题的经典算法。它的思路是：生成问题可行区域的一系列邻接极点，使得目标函数值不断改进。
（4）最大流量问题要求找出一个网络中可能存在的最大流量，网络是包含一个源点和一个汇点的加权有向图。
（5）Ford-Fulkerson 法是利用迭代改进技术求解最大流量问题的经典算法。最短增益路径法通过一种广度优先查找的方式对网络的顶点做标记，从而实现了上述思想。
（6）Ford-Fulkerson 法也可以求出给定网络的最小割。
（7）最大基数匹配是图中边的最大子集，该子集中任何两条边都不共顶点。对于二分图来说，可以对之前求得的匹配进行一系列增益来获得这两个子集。
（8）稳定婚姻问题要求基于给定的匹配优先级，求出两个 n 元素集合的元素之间的稳定匹配。该问题可以用 Gale-Shapley 算法求解，而且总有解。


## 算法能力的极限

在实际开发中，会遇到许多算法，可以求解各种各样的问题。我们必须公正地评价算法作为问题求解工具的作用：它们是极其强大的指令，用现代计算机来执行时尤其如此。但算法的能力并不是没有极限的。我们会看到：有些问题是无法用任何算法来求解的；有些问题可以用算法求解，但无法在多项式的时间内获得答案；有些问题可以在多项式的时间内用算法求解，但往往局限于最优情况。


### 决策树

### P、NP 和 NP 完全问题

### 小结

（1）对于求解某个特定问题的一类算法，下界指出了任何属于这个类型的算法所能够具有的最佳效率。
（2）平凡下界基于对问题输入中必须要处理的项进行计数，同时对必须要输出的项进行计数。
（3）信息论下界常常是通过决策树机制得到的。这个技术对于基于比较的排序和查找算法特别有效。具体来说：
1）在最坏的情况下，任何基于比较的通用排序算法至少必须要执行 logn! ≈ nlogn 次键值比较。
2）在最坏的情况下，任何基于比较的查找有序数组的通用算法至少必须要执行 log(n+1) 次键值比较。
（4）敌手法在建立下界时遵循的是一种有恶意的敌手逻辑，它总是试图把算法推向最消耗时间的路径。
（5）也可以用化简法来建立下界，也就是说，把一个具有已知下界的问题化简为所讨论的问题。
（6）复杂性理论试图按照问题的计算复杂性来对它们分类。它们主要可以分成易解的和难解的两类问题，也就是能在多项式时间内求解的问题和不能在多项式时间内求解的问题。纯粹出于技术上的原因，复杂性理论关注的是判定问题，就是能够回答 “是” 或 “否” 的问题。
（7）停机问题是一个无法判定的判定问题实例，也就是说，无法用任何算法求解的。
（8）P 是所有能够在多项式时间内求解的判定问题所构成的类型。而 NP 是那些随意生成的解能够在多项式时间内得到验证的问题所构成的类型。
（9）我们知道 NP 中许多问题是 NP 完全问题：NP 中的所有其他问题都能够在多项式的时间内转化这种问题。库克发表的合取范式可满足性问题第一次证明了一个问题的 NP 完全性。
（10）我们还不知道 P = NP 是否成立，抑或 P 仅仅是 NP 的一个真子集。这是计算机科学理论中最重要的一个待解难题。对已知的几千种 NP 完全问题来说，如果发现了其中任何一个问题的多项式时间算法，也就意味着 P = NP。
（11）数值分析是计算机科学的一个分支，它处理的是求解连续的数学问题。在解大多数这样的问题时，会产生两种误差：截断误差和舍入误差。截断误差是由于用有限来逼近无穷造成的。舍入误差是由于数字计算机在表示数字时的不精确性造成的。
（12）作为两个相近浮点数相减的结果，有可能会发生减法抵消。这回导致相对舍入误差大大增加，因此需要予以避免（要么改变表达式的形式，要么在计算这种差的时候使用更高的精度）。
（13）写一个解二次方程 ax^2 + bx + c = 0 的计算机程序时一项困难的工作。计算平方根的问题可以用牛顿法来解决。减法抵消问题也可以解决，方法是根据系数 b 是正还是负，分别运用不同的公式，并且用双精度来计算判别式 b^2 - 4ac。



## 超越算法能力的极限

许多问题很难用算法求解。但同时，其中很多问题又是如此重要，以至于无法坐视不理。这里介绍几个方法，专门处理这样的难题。

比如这样两种算法设计技术，回溯法（backtracking）和分支界限法（branch-and-bound）。使用这两种算法以后，我们至少可以求解某些组合难题的较大实例。我们可以把这两种策略看作对穷举查找的一个改进。但和穷举查找不同的是，它们每次只构造候选解的一个分量，然后评估这个部分构造解：如果加上剩下的分量也不可能求得一个解，就绝对不会生成剩下的分量。虽然在最坏的情况下，我们还是需要面对穷举查找中遇到的指数级爆炸问题，但这种方法使我们至少可以对某些组合难题的较大实例求解。

回溯法和分支界限法都是以构造一棵状态空间树为基础的，树的节点反映了对一个部分解所做的特定选择。如果可以保证，节点子孙所对应的选择不可能得出问题的一个解，两种技术都会立即停止处理这个节点。两种技术的区别在于它们能够处理的问题类型不同。分支界限法只能应用于最优问题，因为它基于针对一个问题的目标函数，计算其可能值的边界。回溯法并不受这种要求的制约，但在大多数情况下，它处理的是非优化问题。回溯法和分支界限法的另一个区别在于它们生成状态空间树的节点的顺序不同。对于回溯法来说，它的树的生长顺序常常是深度优先的（也就是和 DFS 类似）。分支界限法可以根据多种规则生成节点，其中一种最普通的规则，即 最佳优先规则。



### 回溯法

回溯法的主要思想是每次只构造解的一个分量，然后按照下面的方法来评估这个部分构造解。如果一个部分构造解可以进一步构造而不会违反问题的约束，我们就接受对解的下一个分量所做的第一个合法选择。如果无法对下一分量进行合法的选择，就不必对剩下的任何分量再做任何选择了。在这种情况下，该算法进行回溯，把部分构造解的最后一个分量替换为它的下一个选择。

通过对所做的选择构造一棵所谓的状态空间树，我们很容易实现这种处理。树的根代表了在查找解之前的初始状态。树的第一层节点代表了对解的第一个分量所做的选择，第二层节点代表了对解的第二个分量所做的选择，以此类推。如果一个部分构造解仍然有可能导致一个完整解，我们说这个部分解在树中的相应节点是有希望的（promising）；否则，我们说它是没希望的（nonpromising）。叶子则要么代表了没希望的死胡同，要么代表了算法找到的完整解。在大多数情况下，一个回溯算法的状态空间树是按照深度优先的方式来构造的。如果当前节点是有希望的，通过向部分解添加下一个分量的第一个合法选择，就生成了节点的一个子女，而处理也会转向这个子女节点。如果当前节点变得没希望了，该算法回溯到该节点的父母，考虑部分解的最后一个分量的下一个可能选择。如果这种选择不存在，它再回溯到树的上一层，以此类推。最后，如果该算法找到了问题的一个完整解，它要么就停止了（如果只需要一个解），要么继续查找其他可能的解。

对于回溯法，最后还有三件事要说。首先，这个方法主要用于那些困难的组合问题，这些问题可能存在精确解，但我们无法用高效的算法求解。其次，回溯法和穷举查找法是不同的。对于一个问题的所有实例，穷举法注定都是非常缓慢的。但应用了回溯法之后，我们至少可以希望，对于一些规模不是很小的实例，我们能够在可接受的时间内对问题求解。对于最优问题来说尤其如此，通过对部分构造解的质量进行评估，回溯的思想在最优问题上得到了进一步的强化。最后，即使回溯法没有消去一个问题的状态空间中的任何一个元素，并在结束的时候生成了其中的所有元素，它还是提供了一种特定的解题方法，而这个方法本身也是具有一定价值的。



### 分支界限法

回溯法的中心思想是，一旦推导出无法从问题状态空间树的某个分支产生一个解，我们就立即把这个分支砍掉。由于最优问题是根据某些约束（旅途的长度、所选物品的价值、分配的成本等）寻求目标函数的最大值或最小值，我们在处理这类问题时，回溯的思想可以得到进一步强化。请注意，在最优问题的标准术语中，可行解（feasible solution）是一个位于问题的查找空间中的点，它能够满足问题的所有约束（例如，旅行商问题的一个哈密顿回路，或总重量不超过背包承重量的物品子集），而最优解是一个使目标函数取得最佳值的可行解（例如，最短哈密顿回路或能够装进背包的最有价值的物品子集）。

和回溯法相比，分支界限法需要两个额外的条件：
（1）对于一棵状态空间树的每一个节点所代表的部分解，我们要提供一种方法，计算出通过这个部分解繁衍出的任何解在目标函数上的最佳值边界。
（2）目前求得的最佳解的值。

如果可以得到这些信息，我们可以拿某个节点的边界值和目前求得的最佳解进行比较：如果边界值不能超越（也就说，在最小化问题中不小于，在最大化问题中不大于）目前的最佳解，这个节点就是一个没有希望的节点，需要立即终止（也有人说把树枝剪掉），因为从这个节点生成的解，没有一个能比目前已经得到的解更好。这就是分支界限技术的主要思想。

一般来说，对于一个分支界限算法的状态空间树来说，只要符合下面三种中的一种原因，我们就会终止它在当前节点上的查找路径：
（1）该节点的边界值不能超越目前最佳解的值。
（2）该节点无法代表任何可行解，因为它已经违反了问题的约束。
（3）该节点代表的可行解的子集只包含一个单独的点（因此无法给出更多的选择）。在这种情况下，我们拿这个可行解在目标函数上的值和目前求得的最佳解进行比较，如果新的解更好一些，就用前者替换后者。

和回溯法相比，用分支界限法对问题求解既会带来机遇也会带来挑战：如何选择节点的生成顺序以及如何得到一个好的边界函数。虽然我们前面使用的最佳优先法则是一种明智的方法，但它求解的速度可能会比其他策略更快，也可能不会。（计算机科学有一个分支称为人工智能，它特别关心生成状态空间树的不同策略。）

发现一个好的边界函数往往并不容易。一方面，我们希望这个函数容易计算。但另一方面又不能过于简单，否则，它无法完成它的主要使命，即尽可能地削剪状态空间树的分支。我们可能需要对所讨论问题的各种实例进行大量试验，才能在这两个矛盾的需求之间达成适当的平衡。


### 小结

（1）回溯法和分支界限法是两种算法设计技术，它们求解的是这种问题：随着实例规模的增长，问题的选择次数至少呈指数增长。两种算法每次都只构造解的一个分量，一旦确定当前已经做出的选择无法导出一个解，就会立即终止当前步骤。这种方法使我们能够在可接受的时间内，对 NP 困难问题的许多较大实例求解。
（2）无论是回溯法还是分支界限法，都把状态空间树作为它们的主要机制。状态空间树是一棵有根树，它的节点代表了所讨论问题的部分构造解。一旦能够确认，从和节点子孙相对应的选择中无法求得问题的解，这两种技术都会立即终止该节点。
（3）回溯法在它的大多数应用中，都按照深度优先查找法构造它的状态空间树。如果状态空间树的当前节点所代表的选择序列可以进一步扩展，而且不会违反问题的约束，它就会考虑下一个分量的第一个余下的合法选择。否则，这个方法就会回溯，也就是撤销部分构造解的最后一个分量，并用下一个选择来代替。
（4）分支界限法是一种算法设计技术，它强化了状态空间树的生成方法。也就是估计可能从状态空间树的当前节点中求得的最佳值，如果这个估计值不超过当前过程中已经得到的最佳解，接下来就不会再考虑该节点了。
（5）近似算法常常用来求组合优化难题的近似解。性能比是用来衡量这种近似算法精度的主要度量标准。
（6）最近邻居和多片段启发式算法是两种简单的贪婪算法，用来对旅行商问题近似求解。这两种算法的性能比是没有上界的，哪怕对一种重要的子集--欧几里得图来说，也是如此。
（7）绕树两周和 Christofides 算法利用了图的最小生成树来构造欧拉回路，然后用走捷径的办法将其变换为哈密顿回路（即旅行商问题的近似解）。对于欧几里得图来说，这两种算法的性能比分别是 2 和 1.5。
（8）本地查找启发式算法（包括 2 选、3 选和 Lin-Kernighan 算法）的思路是，用更短的边来替换当前旅途中的边，直到无法替换为止。对于旅行商问题的较大欧几里得实例，这类算法可以在若干秒内求得一个长度仅比最优解多几个百分点的近似解。
（9）背包问题有一种巧妙的贪婪算法，它的基本思想是，按照价值重量比的降序处理输入物品。对于该问题的连续版本来说，该算法总能生成一个精确的最优解。
（10）背包问题的多项式近似方案是一种参数可调的多项式时间算法，可以按照预定义的任意精度生成近似解。
（11）解非线性方程是数值分析中最重要的领域之一。虽然我们没有非线性方程的求根公式（只有少数例外），但有若干算法可以对它们进行求解。
（12）平分法和试位法分别是连续版本的折半查找和插值查找。它们的主要优势在于，算法在每次迭代时，都会把根包括在某个区间里。
（13）牛顿法会生成一个近似根的一个序列，它们都是函数图像的切线在 x 轴上的截距。如果选择了一个较好的初始近似值，该算法一般只需要很少的几次迭代，就能给出方程根的一个高度近似值。







# 算法设计技巧与分析



（Algorithms Design Techniques and Analysis）



作者：阿苏外耶（M. H. Alsuwaiyel）

译者：吴伟昶、方世昌

版次：2004 年 8 月



出版社：电子工业出版社（Publishing House of Electronics Industry）


## 基于递归的技术



### 归纳法



### 分治



### 动态规划



## 最先割技术



### 贪心算法



### 图的遍历

#### 深度优先遍历

#### 广度优先遍历



## 克服困难性



### 回溯法

#### 一般回溯方法

#### 分支界定法




### 随机算法

### 近似算法




























# 算法导论 原书第 3 版



（Introduction to Algorithms Third Edition）



作者：Thomas H. Cormen、Charles E. Leiserson、Ronald L. Rivest、Clifford Stein

译者：殷建平、徐云、王刚、刘晓光、苏明、邹恒明、王宏志

版次：2013 年 1 月第 1 版第 1 次印刷



出版社：机械工业出版社（China Machine Press）



## 分治策略



## 动态规划



## 贪心算法





# 算法设计



（Algorithm Design）



作者：Jon Kleinberg、Eva Tardos

译者：张立昂、屈婉玲

版次：2007 年 3 月第 1 版第 1 次印刷



出版社：清华大学出版社


## 贪心算法



## 分治策略


## 动态规划


## 网络流



## 近似算法


## 局部搜索



## 随机算法










# 算法设计指南 第 2 版



（The Algorithm Design Manual Second Edition）



作者：Steven S. Skiena

译者：谢勰

版次：2017 年 7 月第 1 版第 1 次印刷



出版社：清华大学出版社


## 分治



## 回溯



## 动态规划









